{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"split_fend.ipynb","provenance":[{"file_id":"1-0VXmC-m7nmcqBdsishpXL8F1e3uUuFY","timestamp":1605461211355},{"file_id":"1LXYY3qMiKr5Z_9HVJbEV7cHzS_sTSdMt","timestamp":1603298362334},{"file_id":"1sXTMaWPylC7u4nHw4XJkrm5qPP8FdCqF","timestamp":1598309112299}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"532bd3b493b34657b2bb88e3bf81c1da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1f5d52e5fe5a4f8a9bb2bb1bb20d91a3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_96969b4024db4219a4a0c6f796aef565","IPY_MODEL_eb7fc59bf31544e2bcbe2dba03e5f44a"]}},"1f5d52e5fe5a4f8a9bb2bb1bb20d91a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96969b4024db4219a4a0c6f796aef565":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ed269a6dc80a400b92f1544bbe2c3c76","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db16efa22f9a45a0afc0554ec07ff1ec"}},"eb7fc59bf31544e2bcbe2dba03e5f44a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71251c244bee4d5ab8fa1265d93f7c37","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [00:39&lt;00:00, 14.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_784c3d1b1dd64fadb0a8d3c2990678b6"}},"ed269a6dc80a400b92f1544bbe2c3c76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"db16efa22f9a45a0afc0554ec07ff1ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71251c244bee4d5ab8fa1265d93f7c37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"784c3d1b1dd64fadb0a8d3c2990678b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"2YTK5-rrV0fC"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"eSPlz1tpVm8a"},"source":["# VQA Model\n","\n","This is part (the front end) of a splitted model. It is responsible for precalculating embeddings for both image and language channels and store it to disk along with the answer and some additional information."]},{"cell_type":"code","metadata":{"id":"CkCidpatsu4M"},"source":["import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from PIL import Image\n","from skimage import io\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import json\n","import pprint\n","import numpy as np\n","import time\n","from datetime import timedelta\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4t4gt77EWmPC"},"source":["Mounting shared Google Drive"]},{"cell_type":"code","metadata":{"id":"0LoaoQ7d7XhC","executionInfo":{"status":"ok","timestamp":1605458948841,"user_tz":-60,"elapsed":36012,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"57aeb310-79d0-4829-a758-ae527a83fd7a","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/aidl/lib')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H8J2PbAtvC2r","executionInfo":{"status":"ok","timestamp":1605032451314,"user_tz":-60,"elapsed":3657,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"ebb8c621-2915-4aa4-c065-57f4229ae5c9","colab":{"base_uri":"https://localhost:8080/"}},"source":["! cp '/content/drive/My Drive/aidl/full.zip' .\n","! unzip full.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  full.zip\n","  inflating: mscoco_qtest.txt        \n","  inflating: mscoco_a.json           \n","  inflating: mscoco_q.json           \n","  inflating: mscoco_qtest_full.txt   \n","  inflating: mscoco_qtrain.txt       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u0rNyq_BvRrk","executionInfo":{"status":"ok","timestamp":1605032622260,"user_tz":-60,"elapsed":163045,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"c7727908-8b71-4334-ea12-c8bf7dacb9a2","colab":{"base_uri":"https://localhost:8080/"}},"source":["! wget 'http://images.cocodataset.org/zips/val2014.zip'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-11-10 18:20:59--  http://images.cocodataset.org/zips/val2014.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.89.188\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.89.188|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6645013297 (6.2G) [application/zip]\n","Saving to: ‘val2014.zip’\n","\n","val2014.zip         100%[===================>]   6.19G  41.0MB/s    in 2m 42s  \n","\n","2020-11-10 18:23:41 (39.1 MB/s) - ‘val2014.zip’ saved [6645013297/6645013297]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s-vuA1bPvaqK"},"source":["# This is an attempt to use the train dataset (443,757 triplets).\n","# Failed due to memory constraints in Google Colab\n","\n","! wget 'http://images.cocodataset.org/zips/train2014.zip'\n","! mkdir coco\n","! unzip -qj train2014.zip -d coco\n","! cp '/content/drive/My Drive/aidl/trt/mscoco_train.zip' .\n","! unzip mscoco_train.zip\n","! head mscoco_qtrain.txt > mscoco_qtest.txt\n","! wc -l *.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-zJrEWSWxWI"},"source":["Global Parameters"]},{"cell_type":"code","metadata":{"id":"W0e6NGOM8KJu","executionInfo":{"status":"ok","timestamp":1605459240692,"user_tz":-60,"elapsed":670,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"ce4dae95-76d7-45fa-de1e-d91f5adc8ef7","colab":{"base_uri":"https://localhost:8080/"}},"source":["batch_size = 30\n","\n","#dataset_root = \"/content/model1000_any\"\n","#dataset_root = \"/content/drive/My Drive/aidl\"\n","#dataset_root = \"/content/drive/My Drive/aidl/Dataset100\"\n","#dataset_root = \"/content/drive/My Drive/aidl/model5000_1_20\"\n","#dataset_root = \"/content/drive/My Drive/aidl/model10000_1_20\"\n","#dataset_root = \"/content/drive/My Drive/aidl/model1000_any\"\n","#dataset_root = \"/content/drive/My Drive/aidl/model10000_yes_no\"\n","dataset_root = \"/content\"\n","\n","!ls '$dataset_root'\n","device = torch.device('cuda')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["coco   mscoco_a.json  mscoco_qtest.txt\t mscoco_train.zip\n","drive  mscoco_q.json  mscoco_qtrain.txt  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jJgGAO9aW9_c"},"source":["Custom Data Loader"]},{"cell_type":"code","metadata":{"id":"ReXnBh2Jt784"},"source":["\"\"\"\n","     Data structure:\n","\n","     root_dir\n","        |_ mscoco_qtrain.txt [list of question IDs for training]\n","        |_ mscoco_qtest.txt  [list of question IDs for testing]\n","        |_ mscoco_q.json     [json of questions]\n","        |_ mscoco_a.json     [json of annotations]\n","        |_ coco              [subdirectory for images]\n","            |_ image 1\n","            |_ image 2\n","              ...\n","            |_ image n\n","\n","\"\"\"\n","\n","class preProcess(Dataset):\n","#\n","#   _ _ i n i t _ _\n","#\n","    def __init__(self, root_dir, train=False, transform=None):\n","        \"\"\"\n","        Args:\n","            root_dir (string): root directory for the data           \n","            train (bool, optional): choose training or testing datasets\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","\n","        super().__init__()\n","\n","        # Define some constants to access files\n","        #self.image_prefix = \"COCO_val2014_\"\n","        self.image_prefix = \"COCO_train2014_\"\n","        self.image_postfix = \".jpg\"\n","        self.image_subdir = 'coco'\n","        self.questions_list_train_fname = 'mscoco_qtrain.txt'\n","        self.questions_list_test_fname = 'mscoco_qtest.txt'\n","        self.questions_fname = 'mscoco_q.json'\n","        self.annotations_fname = 'mscoco_a.json'\n","\n","        # Store parameters as class attributes\n","        self.root_dir = root_dir\n","        self.train = train\n","        self.transform = transform\n","\n","        # Load questions json file\n","        fqfname = os.path.join(self.root_dir, self.questions_fname)\n","        self.questions = json.load(open(fqfname, 'r'))\n","\n","        # Load annotations json file\n","        fqfname = os.path.join(self.root_dir, self.annotations_fname)\n","        self.annotations = json.load(open(fqfname, 'r'))\n","\n","        # Compute list of unique answers (train + test)\n","        fqfname = os.path.join(self.root_dir, self.questions_list_train_fname)\n","        with open(fqfname) as f:\n","          tmp = f.read().splitlines()\n","        ql_train = list(map(int, tmp))\n","\n","        fqfname = os.path.join(self.root_dir, self.questions_list_test_fname)\n","        with open(fqfname) as f:\n","          tmp = f.read().splitlines()\n","        ql_test = list(map(int, tmp))\n","\n","        ql_global = set(ql_train + ql_test)\n","\n","        self.annotation_map = {}\n","        self.annotation_classdist = {}\n","        annotation_id = 0\n","        for a in self.annotations:\n","            if a['question_id'] in ql_global:\n","                if not(a['multiple_choice_answer'] in self.annotation_map):\n","                    self.annotation_map[a['multiple_choice_answer']] = annotation_id\n","                    annotation_id += 1\n","                self.annotation_classdist.update({a['multiple_choice_answer'] : self.annotation_classdist.get(a['multiple_choice_answer'],0) + 1})\n","\n","        #print (self.annotation_map)\n","        #print (self.annotation_classdist)\n","\n","        print(\"Dataset: training {} / testing {}\".format(len(ql_train), len(ql_test)))\n","\n","        # Depending on self.train, assign either training question list or\n","        #   testing question list\n","        if (self.train):\n","            self.questions_list = ql_train\n","        else:\n","            self.questions_list = ql_test\n","#\n","#   _ _ l e n _ _\n","#\n","    def __len__(self):\n","        return len(self.questions_list)\n","#\n","#   _ _ g e t i t e m _ _\n","#\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        # Get question_id from the list\n","        question_id = self.questions_list[idx]\n","\n","        # Find corresponding question and annotation\n","        #   (use next() to get a single value from the list comprehension)\n","        question = next(x for x in self.questions if x['question_id'] == question_id)\n","        annotation = next(a for a in self.annotations if a['question_id'] == question_id)\n","\n","        image_id = question['image_id']\n","        file_name = self.image_prefix+(\"0\"*12+str(image_id))[-12:]+self.image_postfix\n","        fqfname = os.path.join(self.root_dir,self.image_subdir,file_name)\n","        image = Image.open(fqfname)\n"," \n","        # Fix B&W images\n","        if image.mode != 'RGB':\n","            image = image.convert('RGB')\n","\n","        # Apply transformation if there is any\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # Translate annotation to its ID\n","        annotation_ID = self.annotation_map[annotation['multiple_choice_answer']]\n","\n","        metadata = {}\n","        metadata[\"image_id\"] = image_id\n","        metadata[\"filename\"] = file_name\n","        metadata[\"question_text\"] = question['question']\n","        metadata[\"question_id\"] = question_id\n","        metadata[\"annotation_text\"] = annotation['multiple_choice_answer']\n","        metadata[\"annotation_id\"] = annotation_ID\n","        metadata[\"question_type\"] = annotation['question_type']\n","        metadata[\"answer_type\"] = annotation['answer_type']\n","\n","        # return tuple: image, question text, answer text\n","        return image, question['question'], annotation_ID, metadata"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HK1KKV4koYQH"},"source":["Image Embeddings (pretrained VGG-16)"]},{"cell_type":"code","metadata":{"id":"kEtCuk4yrUtG","executionInfo":{"status":"ok","timestamp":1605459328566,"user_tz":-60,"elapsed":15405,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"dbc8c66d-14ab-425a-8a67-e9219bf9c3fb","colab":{"base_uri":"https://localhost:8080/","height":861,"referenced_widgets":["532bd3b493b34657b2bb88e3bf81c1da","1f5d52e5fe5a4f8a9bb2bb1bb20d91a3","96969b4024db4219a4a0c6f796aef565","eb7fc59bf31544e2bcbe2dba03e5f44a","ed269a6dc80a400b92f1544bbe2c3c76","db16efa22f9a45a0afc0554ec07ff1ec","71251c244bee4d5ab8fa1265d93f7c37","784c3d1b1dd64fadb0a8d3c2990678b6"]}},"source":["from torchvision import models, transforms\n","\n","model = models.vgg16(pretrained=True)\n","model.to(device)\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"532bd3b493b34657b2bb88e3bf81c1da","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"dcdTpEu5rltd"},"source":["import torch.nn as nn\n","class ImageEmbedding(nn.Module):\n","\n","    def __init__(self, base_model):\n","        super().__init__()\n","        self.features = base_model.features\n","        self.avgpool = base_model.avgpool\n","        self.classifier = base_model.classifier\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        for i, layer in enumerate(self.classifier):\n","            x = layer(x)\n","            if i == 3:\n","                break\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aW5KbJlMyw-k"},"source":["Text Embeddings (Google Universal Sentence Encoder)"]},{"cell_type":"code","metadata":{"id":"v3Z8S5zEvOOC","executionInfo":{"status":"ok","timestamp":1605459429190,"user_tz":-60,"elapsed":75791,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"58fdefb6-35f4-4591-b796-f21bea65dd2f","colab":{"base_uri":"https://localhost:8080/"}},"source":["from absl import logging\n","\n","import tensorflow as tf\n","\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import re\n","\n","module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n","\n","sentence_embedding_generator = hub.load(module_url)\n","print (\"module %s loaded\" % module_url)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fYaWfmw_Xihl"},"source":["Training VQA Model"]},{"cell_type":"code","metadata":{"id":"uUj-bPOfIUb1","outputId":"222a29d0-d594-4ddd-b396-1e2cf779b125","colab":{"base_uri":"https://localhost:8080/"}},"source":["def preProcessData(dataloader):\n","    t = transforms.ToTensor()\n","\n","    image_embeddings_batch = []\n","    question_embeddings_batch = []\n","    annotations_batch = []\n","    metadatas = []\n","    for batch, (image, question, annotation, metadata) in enumerate(dataloader):\n","        print (batch+1)\n","        image = image.to(device)\n","        image_embedding = image_embedding_extractor.forward(image)\n","        image_embeddings_batch.append(image_embedding)\n","\n","        question_embedding = sentence_embedding_generator(question).numpy()\n","        question_embedding = t(question_embedding)\n","        question_embedding = question_embedding.squeeze_(0).to(device)\n","        question_embeddings_batch.append(question_embedding)\n","\n","        annotations_batch.append(annotation)\n","\n","        m = [{} for i in range(len(metadata['question_id']))]\n","\n","        for k,v in metadata.items():\n","          for i in range(len(v)):\n","            m[i][k] = v[i].item() if isinstance(v[i],torch.Tensor) else v[i]\n","        \n","        metadatas.extend(m)\n","        \n","\n","\n","    image_embeddings = torch.cat(image_embeddings_batch,dim=0)\n","    question_embeddings = torch.cat(question_embeddings_batch,dim=0)\n","    annotations = torch.cat(annotations_batch,dim=0)\n","\n","    return image_embeddings, question_embeddings, annotations, metadatas\n","\n","img_size = 512\n","\n","transform = transforms.Compose([\n","                                transforms.Resize(img_size),\n","                                transforms.CenterCrop(img_size),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                     std=[0.229, 0.224, 0.225])\n","                            ])\n","\n","\n","\n","# Create Dataset & Dataloader\n","ds = preProcess(dataset_root,train=True,transform=transform)\n","dl = DataLoader(ds,batch_size=batch_size,shuffle=False,num_workers=4)\n","\n","torch.save(ds.annotation_map,os.path.join(dataset_root,'annotation_map.save'))\n","\n","test_dataset = preProcess(dataset_root,train=False,transform=transform)\n","test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)\n","\n","image_embedding_extractor = ImageEmbedding(model)\n","for p in image_embedding_extractor.parameters():\n","    p.requires_grad = False\n","\n","start_time = time.time()\n","image_embeddings, question_embeddings, annotations, metadatas = preProcessData(dl)\n","elapsed_time = time.time() - start_time\n","print (\"Total elapsed time.    : {}\".format(str(timedelta(seconds=elapsed_time))))\n","print(\"{} samples in {:,.0f} seconds : {:4.1f} samples/sec\".format(len(ds),\n","                                                                   elapsed_time,len(ds)/elapsed_time))\n","torch.save(image_embeddings,os.path.join(dataset_root,'image_embeddings_train.save'))\n","torch.save(question_embeddings,os.path.join(dataset_root,'question_embeddings_train.save'))\n","torch.save(annotations,os.path.join(dataset_root,'annotations_train.save'))\n","torch.save(metadatas,os.path.join(dataset_root,'metadatas_train.save'))\n","\n","#image_embeddings, question_embeddings, annotations, metadatas = preProcessData(test_loader)\n","\n","#torch.save(image_embeddings,os.path.join(dataset_root,'image_embeddings_test.save'))\n","#torch.save(question_embeddings,os.path.join(dataset_root,'question_embeddings_test.save'))\n","#torch.save(annotations,os.path.join(dataset_root,'annotations_test.save'))\n","#torch.save(metadatas,os.path.join(dataset_root,'metadatas_test.save'))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset: training 443757 / testing 10\n","Dataset: training 443757 / testing 10\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","640\n","641\n","642\n","643\n","644\n","645\n","646\n","647\n","648\n","649\n","650\n","651\n","652\n","653\n","654\n","655\n","656\n","657\n","658\n","659\n","660\n","661\n","662\n","663\n","664\n","665\n","666\n","667\n","668\n","669\n","670\n","671\n","672\n","673\n","674\n","675\n","676\n","677\n","678\n","679\n","680\n","681\n","682\n","683\n","684\n","685\n","686\n","687\n","688\n","689\n","690\n","691\n","692\n","693\n","694\n","695\n","696\n","697\n","698\n","699\n","700\n","701\n","702\n","703\n","704\n","705\n","706\n","707\n","708\n","709\n","710\n","711\n","712\n","713\n","714\n","715\n","716\n","717\n","718\n","719\n","720\n","721\n","722\n","723\n","724\n","725\n","726\n","727\n","728\n","729\n","730\n","731\n","732\n","733\n","734\n","735\n","736\n","737\n","738\n","739\n","740\n","741\n","742\n","743\n","744\n","745\n","746\n","747\n","748\n","749\n","750\n","751\n","752\n","753\n","754\n","755\n","756\n","757\n","758\n","759\n","760\n","761\n","762\n","763\n","764\n","765\n","766\n","767\n","768\n","769\n","770\n","771\n","772\n","773\n","774\n","775\n","776\n","777\n","778\n","779\n","780\n","781\n","782\n","783\n","784\n","785\n","786\n","787\n","788\n","789\n","790\n","791\n","792\n","793\n","794\n","795\n","796\n","797\n","798\n","799\n","800\n","801\n","802\n","803\n","804\n","805\n","806\n","807\n","808\n","809\n","810\n","811\n","812\n","813\n","814\n","815\n","816\n","817\n","818\n","819\n","820\n","821\n","822\n","823\n","824\n","825\n","826\n","827\n","828\n","829\n","830\n","831\n","832\n","833\n","834\n","835\n","836\n","837\n","838\n","839\n","840\n","841\n","842\n","843\n","844\n","845\n","846\n","847\n","848\n","849\n","850\n","851\n","852\n","853\n","854\n","855\n","856\n","857\n","858\n","859\n","860\n","861\n","862\n","863\n","864\n","865\n","866\n","867\n","868\n","869\n","870\n","871\n","872\n","873\n","874\n","875\n","876\n","877\n","878\n","879\n","880\n","881\n","882\n","883\n","884\n","885\n","886\n","887\n","888\n","889\n","890\n","891\n","892\n","893\n","894\n","895\n","896\n","897\n","898\n","899\n","900\n","901\n","902\n","903\n","904\n","905\n","906\n","907\n","908\n","909\n","910\n","911\n","912\n","913\n","914\n","915\n","916\n","917\n","918\n","919\n","920\n","921\n","922\n","923\n","924\n","925\n","926\n","927\n","928\n","929\n","930\n","931\n","932\n","933\n","934\n","935\n","936\n","937\n","938\n","939\n","940\n","941\n","942\n","943\n","944\n","945\n","946\n","947\n","948\n","949\n","950\n","951\n","952\n","953\n","954\n","955\n","956\n","957\n","958\n","959\n","960\n","961\n","962\n","963\n","964\n","965\n","966\n","967\n","968\n","969\n","970\n","971\n","972\n","973\n","974\n","975\n","976\n","977\n","978\n","979\n","980\n","981\n","982\n","983\n","984\n","985\n","986\n","987\n","988\n","989\n","990\n","991\n","992\n","993\n","994\n","995\n","996\n","997\n","998\n","999\n","1000\n","1001\n","1002\n","1003\n","1004\n","1005\n","1006\n","1007\n","1008\n","1009\n","1010\n","1011\n","1012\n","1013\n","1014\n","1015\n","1016\n","1017\n","1018\n","1019\n","1020\n","1021\n","1022\n","1023\n","1024\n","1025\n","1026\n","1027\n","1028\n","1029\n","1030\n","1031\n","1032\n","1033\n","1034\n","1035\n","1036\n","1037\n","1038\n","1039\n","1040\n","1041\n","1042\n","1043\n","1044\n","1045\n","1046\n","1047\n","1048\n","1049\n","1050\n","1051\n","1052\n","1053\n","1054\n","1055\n","1056\n","1057\n","1058\n","1059\n","1060\n","1061\n","1062\n","1063\n","1064\n","1065\n","1066\n","1067\n","1068\n","1069\n","1070\n","1071\n","1072\n","1073\n","1074\n","1075\n","1076\n","1077\n","1078\n","1079\n","1080\n","1081\n","1082\n","1083\n","1084\n","1085\n","1086\n","1087\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6YQl9Ncc5QKh"},"source":["len(annotations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Id1Cd_7Q6fWT"},"source":["Obtain a list with de 1000 most frequent answers and save it"]},{"cell_type":"code","metadata":{"id":"zuBIX3tRUxm1"},"source":["freq = torch.bincount(annotations)\n","v, i = torch.topk(freq,1000)\n","print(\"1000 most frequent answer account for {:2.0f}% of the answers\".format(100*v.sum().item()/len(annotations)))\n","f = list(map(lambda x: idx2str[x],i))\n","torch.save(f,'freq.save')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThodgytBEMRY","executionInfo":{"status":"ok","timestamp":1604504577143,"user_tz":-60,"elapsed":72295,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"fae10f2c-ee0d-4f0f-90d1-b3ed49efa2d5","colab":{"base_uri":"https://localhost:8080/"}},"source":["!zip vgg_GUSE_embeddings.zip annotation_map.save image_embeddings.save question_embeddings.save annotations.save metadatas.save freq.save"],"execution_count":null,"outputs":[{"output_type":"stream","text":["updating: annotation_map.save (deflated 49%)\n","updating: image_embeddings.save (deflated 69%)\n","updating: question_embeddings.save (deflated 8%)\n","updating: annotations.save (deflated 81%)\n","updating: metadatas.save (deflated 73%)\n","  adding: freq.save (deflated 54%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eHwKNheUZZIo","executionInfo":{"status":"ok","timestamp":1604503488925,"user_tz":-60,"elapsed":708,"user":{"displayName":"Rafael Garcia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTAeWlRjnuwxJhQkodqOIU5gtR3BaDW8HYp8DJ=s64","userId":"04355349878264414146"}},"outputId":"b4cd53b7-fe64-41a1-a32f-b100144cb16b","colab":{"base_uri":"https://localhost:8080/"}},"source":["freq = torch.bincount(annotations)\n","v, i = torch.topk(freq,1000)\n","#for s,n in zip(f[:100],v[:100]):\n","#    print (s,\"\\t\",n.item())\n","\n","print(\"1000 most frequent annswer account for {:2.0f}% of the answers\".format(100*v.sum().item()/len(annotations)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000 most frequent annswer account for 86% of the answers\n"],"name":"stdout"}]}]}